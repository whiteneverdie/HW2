org.apache.spark.sql.AnalysisException: Queries with streaming sources must be executed with writeStream.start();;
kafka
  org.apache.spark.sql.catalyst.analysis.UnsupportedOperationChecker$.throwError(UnsupportedOperationChecker.scala:389)
  org.apache.spark.sql.catalyst.analysis.UnsupportedOperationChecker$.$anonfun$checkForBatch$1(UnsupportedOperationChecker.scala:38)
  org.apache.spark.sql.catalyst.analysis.UnsupportedOperationChecker$.$anonfun$checkForBatch$1$adapted(UnsupportedOperationChecker.scala:36)
  org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)
  org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:125)
  org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:125)
  scala.collection.immutable.List.foreach(List.scala:431)
  org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:125)
  org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:125)
  org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:125)
  scala.collection.immutable.List.foreach(List.scala:431)
  org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:125)
  org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:125)
  org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:125)
  scala.collection.immutable.List.foreach(List.scala:431)
  org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:125)
  org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:125)
  org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:125)
  scala.collection.immutable.List.foreach(List.scala:431)
  org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:125)
  org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:125)
  org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:125)
  scala.collection.immutable.List.foreach(List.scala:431)
  org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:125)
  org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:125)
  org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:125)
  scala.collection.immutable.List.foreach(List.scala:431)
  org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:125)
  org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:125)
  org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:125)
  scala.collection.immutable.List.foreach(List.scala:431)
  org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:125)
  org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:125)
  org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:125)
  scala.collection.immutable.List.foreach(List.scala:431)
  org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:125)
  org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:125)
  org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:125)
  scala.collection.immutable.List.foreach(List.scala:431)
  org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:125)
  org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:125)
  org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:125)
  scala.collection.immutable.List.foreach(List.scala:431)
  org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:125)
  org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:125)
  org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:125)
  scala.collection.immutable.List.foreach(List.scala:431)
  org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:125)
  org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:125)
  org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:125)
  scala.collection.immutable.List.foreach(List.scala:431)
  org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:125)
  org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:125)
  org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:125)
  scala.collection.immutable.List.foreach(List.scala:431)
  org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:125)
  org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:125)
  org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:125)
  scala.collection.immutable.List.foreach(List.scala:431)
  org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:125)
  org.apache.spark.sql.catalyst.analysis.UnsupportedOperationChecker$.checkForBatch(UnsupportedOperationChecker.scala:36)
  org.apache.spark.sql.execution.QueryExecution.assertSupported(QueryExecution.scala:52)
  org.apache.spark.sql.execution.QueryExecution.withCachedData$lzycompute(QueryExecution.scala:63)
  org.apache.spark.sql.execution.QueryExecution.withCachedData(QueryExecution.scala:61)
  org.apache.spark.sql.execution.QueryExecution.optimizedPlan$lzycompute(QueryExecution.scala:67)
  org.apache.spark.sql.execution.QueryExecution.optimizedPlan(QueryExecution.scala:67)
  org.apache.spark.sql.execution.QueryExecution.sparkPlan$lzycompute(QueryExecution.scala:73)
  org.apache.spark.sql.execution.QueryExecution.sparkPlan(QueryExecution.scala:69)
  org.apache.spark.sql.execution.QueryExecution.executedPlan$lzycompute(QueryExecution.scala:78)
  org.apache.spark.sql.execution.QueryExecution.executedPlan(QueryExecution.scala:78)
  org.apache.spark.sql.Dataset.withAction(Dataset.scala:3365)
  org.apache.spark.sql.Dataset.head(Dataset.scala:2550)
  org.apache.spark.sql.Dataset.head(Dataset.scala:2557)
  org.apache.spark.sql.Dataset.first(Dataset.scala:2564)
  org.apache.spark.ml.feature.VectorAssembler$.getVectorLengthsFromFirstRow(VectorAssembler.scala:200)
  org.apache.spark.ml.feature.VectorAssembler$.getLengths(VectorAssembler.scala:226)
  org.apache.spark.ml.feature.VectorAssembler.transform(VectorAssembler.scala:96)
  org.apache.spark.ml.PipelineModel.$anonfun$transform$1(Pipeline.scala:306)
  scala.collection.IndexedSeqOptimized.foldLeft(IndexedSeqOptimized.scala:60)
  scala.collection.IndexedSeqOptimized.foldLeft$(IndexedSeqOptimized.scala:68)
  scala.collection.mutable.ArrayOps$ofRef.foldLeft(ArrayOps.scala:198)
  org.apache.spark.ml.PipelineModel.transform(Pipeline.scala:306)
  ammonite.$sess.cmd61$Helper.<init>(cmd61.sc:1)
  ammonite.$sess.cmd61$.<init>(cmd61.sc:7)
  ammonite.$sess.cmd61$.<clinit>(cmd61.sc:-1)