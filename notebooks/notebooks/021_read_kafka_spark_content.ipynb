{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:2.4.5`\n",
    "import $ivy.`org.apache.spark::spark-mllib:2.4.5`\n",
    "import $ivy.`org.apache.spark::spark-streaming-kafka-0-10:2.4.5`\n",
    "import $ivy.`org.apache.spark::spark-sql-kafka-0-10:2.4.5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.log4j.{Level, Logger}\n",
    "Logger.getLogger(\"org\").setLevel(Level.OFF)\n",
    "\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "import org.apache.spark.sql.streaming.Trigger\n",
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "def killAll() = {\n",
    "    SparkSession\n",
    "        .active\n",
    "        .streams\n",
    "        .active\n",
    "        .foreach { x =>\n",
    "                    val desc = x.lastProgress.sources.head.description\n",
    "                    x.stop\n",
    "                    println(s\"Stopped ${desc}\")\n",
    "        }               \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val spark = {\n",
    "  NotebookSparkSession.builder()\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.executor.instances\", \"2\")\n",
    "    .config(\"spark.executor.memory\", \"2g\")\n",
    "    .getOrCreate()\n",
    "}\n",
    "\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val df_content_test = spark\n",
    "  .readStream\n",
    "  .format(\"kafka\")\n",
    "  .option(\"kafka.bootstrap.servers\", \"172.27.1.16:9092\")\n",
    "  .option(\"subscribe\", \"content_topic_example\")\n",
    "  .option(\"enable.auto.commit\", \"false\")\n",
    "  .option(\"auto.offset.reset\",\"earliest\")\n",
    "  .option(\"startingOffsets\", \"earliest\")\n",
    "//   .option(\"auto.offset.reset\",\"latest\")\n",
    "//   .option(\"endingOffsets\", \"latest\")\n",
    "//   .option(\"maxOffsetsPerTrigger\", \"10\")\n",
    "  .load()\n",
    "  .select($\"timestamp\" cast \"timestamp\" as \"contentTime\" , $\"key\" cast \"string\" as \"objID\", $\"value\" cast \"string\")\n",
    "\n",
    "def createConsoleSink(df: DataFrame) = {\n",
    "    df\n",
    "    .writeStream\n",
    "    .format(\"console\")\n",
    "    .trigger(Trigger.ProcessingTime(\"2 seconds\"))\n",
    "    .option(\"truncate\", \"false\")\n",
    "    .option(\"numRows\", \"10\")\n",
    "}\n",
    "\n",
    "val sink = createConsoleSink(df_content_test)\n",
    "val sq = sink.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cmd0.sc:1: not found: value killAll\n",
      "val res0 = killAll()\n",
      "           ^Compilation Failed"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Compilation Failed"
     ]
    }
   ],
   "source": [
    "killAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.clearCache()\n",
    "spark.close()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.12",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
