{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                  \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                    \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                                   \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                             \u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:2.4.5`\n",
    "import $ivy.`org.apache.spark::spark-mllib:2.4.5`\n",
    "import $ivy.`org.apache.spark::spark-streaming-kafka-0-10:2.4.5`\n",
    "import $ivy.`org.apache.spark::spark-sql-kafka-0-10:2.4.5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.streaming.Trigger\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.DataFrame\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.SparkSession\n",
       "\n",
       "\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mkillAll\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.log4j.{Level, Logger}\n",
    "Logger.getLogger(\"org\").setLevel(Level.OFF)\n",
    "\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "import org.apache.spark.sql.streaming.Trigger\n",
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "def killAll() = {\n",
    "    SparkSession\n",
    "        .active\n",
    "        .streams\n",
    "        .active\n",
    "        .foreach { x =>\n",
    "                    val desc = x.lastProgress.sources.head.description\n",
    "                    x.stop\n",
    "                    println(s\"Stopped ${desc}\")\n",
    "        }               \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spark-stubs\n",
      "Getting spark JARs\n",
      "Creating SparkSession\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a target=\"_blank\" href=\"http://774cd6601c93:4041\">Spark UI</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@22acac0d\n",
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = {\n",
    "  NotebookSparkSession.builder()\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.executor.instances\", \"2\")\n",
    "    .config(\"spark.executor.memory\", \"2g\")\n",
    "    .getOrCreate()\n",
    "}\n",
    "\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mdf_feedback_test\u001b[39m: \u001b[32mDataFrame\u001b[39m = [useID: string, objID: string ... 1 more field]\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mcreateConsoleSink\u001b[39m\n",
       "\u001b[36msink\u001b[39m: \u001b[32mstreaming\u001b[39m.\u001b[32mDataStreamWriter\u001b[39m[\u001b[32mRow\u001b[39m] = org.apache.spark.sql.streaming.DataStreamWriter@3561177c\n",
       "\u001b[36msq\u001b[39m: \u001b[32mstreaming\u001b[39m.\u001b[32mStreamingQuery\u001b[39m = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@6d151707"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df_feedback_test = spark\n",
    "  .readStream\n",
    "  .format(\"kafka\")\n",
    "  .option(\"kafka.bootstrap.servers\", \"172.27.1.16:9092\")\n",
    "  .option(\"subscribe\", \"feedback_topic_test\")\n",
    "//   .option(\"startingOffsets\", \"\"\" { \"feedback_topic\": { \"0\": 1 } } \"\"\")\n",
    "//   .option(\"endingOffsets\",   \"\"\" { \"feedback_topic\": { \"0\": 100 } }  \"\"\")\n",
    "   .option(\"enable.auto.commit\", \"false\")\n",
    "   .option(\"auto.offset.reset\", \"earliest\")\n",
    "   .option(\"startingOffsets\", \"earliest\")\n",
    "//   .option(\"endingOffsets\", \"latest\")\n",
    "  .load()\n",
    "  .select(split($\"key\", \"_\").getItem(0) as \"useID\", split($\"key\", \"_\").getItem(1) as \"objID\", $\"value\" cast \"string\")\n",
    "\n",
    "def createConsoleSink(df: DataFrame) = {\n",
    "    df\n",
    "    .writeStream\n",
    "    .format(\"console\")\n",
    "    .trigger(Trigger.ProcessingTime(\"2 seconds\"))\n",
    "    .option(\"truncate\", \"false\")\n",
    "    .option(\"numRows\", \"10\")\n",
    "}\n",
    "\n",
    "val sink = createConsoleSink(df_feedback_test)\n",
    "val sq = sink.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+-----+-----+-----+\n",
      "|useID|objID|value|\n",
      "+-----+-----+-----+\n",
      "+-----+-----+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>\n",
       "var comm = Jupyter.notebook.kernel.comm_manager.new_comm('cancel-stage-6d1c21e2-ea83-4cb5-a9be-281201383336', {});\n",
       "\n",
       "function cancelStage(stageId) {\n",
       "  console.log('Cancelling stage ' + stageId);\n",
       "  comm.send({ 'stageId': stageId });\n",
       "}\n",
       "</script>\n",
       "          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">start at cmd3.sc:25</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+--------+-------+---------------------------------------------------------------------+\n",
      "|useID   |objID  |value                                                                |\n",
      "+--------+-------+---------------------------------------------------------------------+\n",
      "|11700150|1536025|{\"membership_status\":\"A\",\"feedback\":[\"Ignored\"]}                     |\n",
      "|13798707|330    |{\"membership_status\":\"U\",\"feedback\":[\"Liked\"]}                       |\n",
      "|2820138 |18010  |{\"membership_status\":\"U\",\"feedback\":[\"Disliked\",\"Clicked\",\"Ignored\"]}|\n",
      "|14653794|6305   |{\"membership_status\":\"U\",\"feedback\":[\"Disliked\",\"Ignored\"]}          |\n",
      "|14277726|1241   |{\"membership_status\":\"U\",\"feedback\":[\"Ignored\"]}                     |\n",
      "|7559148 |6005   |{\"membership_status\":\"A\",\"feedback\":[\"Clicked\",\"Liked\"]}             |\n",
      "|10716810|330    |{\"membership_status\":\"P\",\"feedback\":[\"Clicked\",\"Unliked\"]}           |\n",
      "|12567543|8140   |{\"membership_status\":\"U\",\"feedback\":[\"Ignored\"]}                     |\n",
      "|2853249 |7838   |{\"membership_status\":\"U\",\"feedback\":[\"Clicked\"]}                     |\n",
      "|6216207 |9502530|{\"membership_status\":\"U\",\"feedback\":[\"Ignored\"]}                     |\n",
      "+--------+-------+---------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sq.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cmd0.sc:1: not found: value killAll\n",
      "val res0 = killAll()\n",
      "           ^Compilation Failed"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Compilation Failed"
     ]
    }
   ],
   "source": [
    "killAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.clearCache()\n",
    "spark.close()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.12",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
